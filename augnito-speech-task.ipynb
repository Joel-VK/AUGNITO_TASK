{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9770020,"sourceType":"datasetVersion","datasetId":5984048}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Step 1: Install Necessary Libraries\n!pip install transformers torchaudio","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-31T11:08:57.325298Z","iopub.execute_input":"2024-10-31T11:08:57.326408Z","iopub.status.idle":"2024-10-31T11:09:10.830553Z","shell.execute_reply.started":"2024-10-31T11:08:57.326357Z","shell.execute_reply":"2024-10-31T11:09:10.829322Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.45.1)\nRequirement already satisfied: torchaudio in /opt/conda/lib/python3.10/site-packages (2.4.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.25.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.0)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from torchaudio) (2.4.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.8.30)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->torchaudio) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->torchaudio) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->torchaudio) (3.1.4)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->torchaudio) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->torchaudio) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import logging\nimport torch\n\nlogging.set_verbosity_error()  # Suppresses detailed logs for space\ntorch.cuda.empty_cache()       # Empties GPU cache if used\n\n!rm -rf ~/.cache/huggingface  # Clear Hugging Face cache\n!rm -rf ~/.cache/torch        # Clear PyTorch cache\n\n!du -h /kaggle/working  # List file sizes in the working directory\n!rm -rf /kaggle/working/large_file_or_directory  # Replace with the path to delete\n\nimport shutil\nshutil.rmtree('/root/.cache/huggingface', ignore_errors=True)\nshutil.rmtree('/root/.cache/torch', ignore_errors=True)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-31T17:39:04.367316Z","iopub.execute_input":"2024-10-31T17:39:04.367694Z","iopub.status.idle":"2024-10-31T17:39:08.492005Z","shell.execute_reply.started":"2024-10-31T17:39:04.367660Z","shell.execute_reply":"2024-10-31T17:39:08.490693Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"4.0K\t/kaggle/working/.virtual_documents\n1.1G\t/kaggle/working/results/checkpoint-2240\n1.1G\t/kaggle/working/results/checkpoint-13440\n1.1G\t/kaggle/working/results/checkpoint-19040\n1.1G\t/kaggle/working/results/checkpoint-8960\n1.1G\t/kaggle/working/results/checkpoint-10080\n1.1G\t/kaggle/working/results/checkpoint-12320\n1.1G\t/kaggle/working/results/checkpoint-16800\n1.1G\t/kaggle/working/results/checkpoint-15680\n1.1G\t/kaggle/working/results/checkpoint-5600\n1.1G\t/kaggle/working/results/checkpoint-4480\n1.1G\t/kaggle/working/results/checkpoint-11200\n486M\t/kaggle/working/results/checkpoint-21280\n1.1G\t/kaggle/working/results/checkpoint-7840\n1.1G\t/kaggle/working/results/checkpoint-14560\n1.1G\t/kaggle/working/results/checkpoint-17920\n1.1G\t/kaggle/working/results/checkpoint-3360\n1.1G\t/kaggle/working/results/checkpoint-20160\n1.1G\t/kaggle/working/results/checkpoint-1120\n1.1G\t/kaggle/working/results/checkpoint-6720\n20G\t/kaggle/working/results\n20G\t/kaggle/working\n","output_type":"stream"}]},{"cell_type":"code","source":"# Step 1: Import Necessary Libraries\nimport os\nimport pandas as pd\nimport numpy as np\nimport librosa\nimport torch\nfrom torch.utils.data import Dataset\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, accuracy_score\nfrom transformers import Wav2Vec2FeatureExtractor, Wav2Vec2ForSequenceClassification, Trainer, TrainingArguments\n\n# Check if GPU is available\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f'Using device: {device}')\n\n# Step 2: Define the Data Directory and Emotion Labels\ndata_dir = '/kaggle/input/augnito-task-dataset/Emotions'\nemotion_labels = ['Angry', 'Happy', 'Sad', 'Neutral', 'Fearful', 'Disgusted', 'Suprised']\n\n# Step 3: Create a DataFrame with File Paths and Labels\nfile_paths, labels = [], []\nfor emotion in emotion_labels:\n    emotion_dir = os.path.join(data_dir, emotion)\n    if not os.path.isdir(emotion_dir):\n        print(f\"Warning: Directory for emotion '{emotion}' not found.\")\n        continue\n    for root, _, files in os.walk(emotion_dir):\n        for file in files:\n            if file.endswith('.wav'):\n                file_path = os.path.join(root, file)\n                file_paths.append(file_path)\n                labels.append(emotion)\n\nif not file_paths:\n    raise ValueError(\"No .wav files found. Check the data directory path.\")\n\n# Create DataFrame\ndf = pd.DataFrame({'file_path': file_paths, 'emotion': labels})\ndf['label'] = df['emotion'].astype('category').cat.codes\nlabel2id = {label: idx for idx, label in enumerate(emotion_labels)}\nid2label = {v: k for k, v in label2id.items()}\n\n# Step 4: Dataset Preparation\nclass EmotionDataset(Dataset):\n    def __init__(self, dataframe, feature_extractor, max_length=16000):\n        self.dataframe = dataframe.reset_index(drop=True)\n        self.feature_extractor = feature_extractor\n        self.max_length = max_length\n\n    def __len__(self):\n        return len(self.dataframe)\n\n    def __getitem__(self, idx):\n        file_path = self.dataframe.loc[idx, 'file_path']\n        label = self.dataframe.loc[idx, 'label']\n        speech_array, _ = librosa.load(file_path, sr=16000)\n        inputs = self.feature_extractor(speech_array, sampling_rate=16000, return_tensors=\"pt\", padding=\"longest\")\n        inputs['input_values'] = inputs['input_values'].squeeze(0)  # Ensure input is 1D\n        return {\n            \"input_values\": inputs[\"input_values\"],\n            \"labels\": torch.tensor(label, dtype=torch.long)\n        }\n\n# Step 5: Split Data into Train, Validation, and Test Sets\ntrain_df, test_df = train_test_split(df, test_size=0.15, stratify=df['label'], random_state=42)\ntrain_df, val_df = train_test_split(train_df, test_size=0.1765, stratify=train_df['label'], random_state=42)\n\nfeature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(\"facebook/wav2vec2-base\")\ntrain_dataset = EmotionDataset(train_df, feature_extractor)\nval_dataset = EmotionDataset(val_df, feature_extractor)\ntest_dataset = EmotionDataset(test_df, feature_extractor)\n\n# Verify dataset sizes\nprint(f\"Train Dataset Size: {len(train_dataset)}\")\nprint(f\"Validation Dataset Size: {len(val_dataset)}\")\nprint(f\"Test Dataset Size: {len(test_dataset)}\")\n\n# Step 6: Load Pretrained Wav2Vec2 Base Model with a Classification Head\nmodel = Wav2Vec2ForSequenceClassification.from_pretrained(\n    \"facebook/wav2vec2-base\",\n    num_labels=len(emotion_labels),\n    problem_type=\"single_label_classification\"\n).to(device)\n\n# Unfreeze the last few layers for fine-tuning\nfor name, param in model.wav2vec2.named_parameters():\n    if not name.startswith(\"encoder.layers.11\"):  # Adjust number of layers as needed\n        param.requires_grad = False\n\n# Step 7: Set up Training Arguments and Trainer\ntraining_args = TrainingArguments(\n    output_dir=\"./results\",\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    learning_rate=1e-3,\n    per_device_train_batch_size=8,  \n    per_device_eval_batch_size=8,\n    num_train_epochs=20,  # Shorten for testing\n    save_total_limit=1,\n    logging_dir=\"./logs\",\n    logging_steps=10,\n    load_best_model_at_end=True,\n     report_to=\"none\"  # Disables wandb logging\n)\n\n# Define metrics for evaluation\ndef compute_metrics(pred):\n    labels = pred.label_ids\n    preds = np.argmax(pred.predictions, axis=1)\n    accuracy = accuracy_score(labels, preds)\n    report = classification_report(\n        labels, preds, labels=list(label2id.values()), target_names=emotion_labels, output_dict=True, zero_division=0\n    )\n    return {\n        'accuracy': accuracy,\n        'precision': report['weighted avg']['precision'],\n        'recall': report['weighted avg']['recall'],\n        'f1': report['weighted avg']['f1-score']\n    }\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n    tokenizer=feature_extractor,\n    compute_metrics=compute_metrics\n)\n\n# Step 8: Train the Model\ntrainer.train()\n\n# Step 9: Evaluate the Fine-Tuned Model on Test Set\ntest_results = trainer.evaluate(test_dataset)\nprint(f\"Test Results: {test_results}\")\n\n# Step 10: Model Predictions and Classification Report\npredictions = trainer.predict(test_dataset)\nprint(classification_report(predictions.label_ids, np.argmax(predictions.predictions, axis=1), target_names=emotion_labels))\n","metadata":{"execution":{"iopub.status.busy":"2024-11-01T00:10:32.986520Z","iopub.execute_input":"2024-11-01T00:10:32.986826Z","iopub.status.idle":"2024-11-01T02:12:40.538792Z","shell.execute_reply.started":"2024-11-01T00:10:32.986793Z","shell.execute_reply":"2024-11-01T02:12:40.537814Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/159 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0ceb726be4a64d4482a3b2f4ba9b1e09"}},"metadata":{}},{"name":"stdout","text":"Train Dataset Size: 8958\nValidation Dataset Size: 1920\nTest Dataset Size: 1920\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.84k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e16b7a70e384d1d816061513e429645"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/configuration_utils.py:302: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/380M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"245e2b1bb3ae42d88a2e2c24ef243925"}},"metadata":{}},{"name":"stderr","text":"Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'projector.bias', 'projector.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='22400' max='22400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [22400/22400 2:00:11, Epoch 20/20]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.408700</td>\n      <td>1.525669</td>\n      <td>0.410417</td>\n      <td>0.475502</td>\n      <td>0.410417</td>\n      <td>0.388822</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.028200</td>\n      <td>1.396975</td>\n      <td>0.517188</td>\n      <td>0.547526</td>\n      <td>0.517188</td>\n      <td>0.511451</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.033100</td>\n      <td>1.407183</td>\n      <td>0.551562</td>\n      <td>0.614815</td>\n      <td>0.551562</td>\n      <td>0.533548</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>1.224000</td>\n      <td>1.120048</td>\n      <td>0.619792</td>\n      <td>0.624538</td>\n      <td>0.619792</td>\n      <td>0.613568</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>1.071800</td>\n      <td>1.136039</td>\n      <td>0.638542</td>\n      <td>0.655762</td>\n      <td>0.638542</td>\n      <td>0.632547</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.723000</td>\n      <td>1.297699</td>\n      <td>0.607292</td>\n      <td>0.656584</td>\n      <td>0.607292</td>\n      <td>0.603721</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.707900</td>\n      <td>1.105451</td>\n      <td>0.658333</td>\n      <td>0.693052</td>\n      <td>0.658333</td>\n      <td>0.656315</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.543800</td>\n      <td>1.234137</td>\n      <td>0.643229</td>\n      <td>0.675100</td>\n      <td>0.643229</td>\n      <td>0.639962</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.547700</td>\n      <td>1.115114</td>\n      <td>0.671354</td>\n      <td>0.683882</td>\n      <td>0.671354</td>\n      <td>0.671523</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.606400</td>\n      <td>1.244289</td>\n      <td>0.666667</td>\n      <td>0.698913</td>\n      <td>0.666667</td>\n      <td>0.663972</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>0.722900</td>\n      <td>1.097946</td>\n      <td>0.681771</td>\n      <td>0.690454</td>\n      <td>0.681771</td>\n      <td>0.682093</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>0.808000</td>\n      <td>1.188766</td>\n      <td>0.663021</td>\n      <td>0.682355</td>\n      <td>0.663021</td>\n      <td>0.659542</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>0.681100</td>\n      <td>1.155894</td>\n      <td>0.675521</td>\n      <td>0.712328</td>\n      <td>0.675521</td>\n      <td>0.677883</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>0.565100</td>\n      <td>1.114513</td>\n      <td>0.691146</td>\n      <td>0.710352</td>\n      <td>0.691146</td>\n      <td>0.688840</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>0.514600</td>\n      <td>1.113576</td>\n      <td>0.690625</td>\n      <td>0.701040</td>\n      <td>0.690625</td>\n      <td>0.690116</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>0.659800</td>\n      <td>1.220085</td>\n      <td>0.687500</td>\n      <td>0.698204</td>\n      <td>0.687500</td>\n      <td>0.685593</td>\n    </tr>\n    <tr>\n      <td>17</td>\n      <td>0.505800</td>\n      <td>1.204507</td>\n      <td>0.685417</td>\n      <td>0.702204</td>\n      <td>0.685417</td>\n      <td>0.684594</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>0.561400</td>\n      <td>1.312525</td>\n      <td>0.690104</td>\n      <td>0.710989</td>\n      <td>0.690104</td>\n      <td>0.688397</td>\n    </tr>\n    <tr>\n      <td>19</td>\n      <td>0.487800</td>\n      <td>1.230088</td>\n      <td>0.704688</td>\n      <td>0.721022</td>\n      <td>0.704688</td>\n      <td>0.703542</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>0.445900</td>\n      <td>1.286837</td>\n      <td>0.702604</td>\n      <td>0.717097</td>\n      <td>0.702604</td>\n      <td>0.701720</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Test Results: {'eval_loss': 1.0372107028961182, 'eval_accuracy': 0.6963541666666667, 'eval_precision': 0.7043298057037982, 'eval_recall': 0.6963541666666667, 'eval_f1': 0.6943641531155033, 'eval_runtime': 40.2873, 'eval_samples_per_second': 47.658, 'eval_steps_per_second': 5.957, 'epoch': 20.0}\n              precision    recall  f1-score   support\n\n       Angry       0.86      0.82      0.84       325\n       Happy       0.64      0.72      0.68       280\n         Sad       0.60      0.62      0.61       307\n     Neutral       0.74      0.53      0.62       325\n     Fearful       0.64      0.86      0.73       269\n   Disgusted       0.68      0.62      0.65       325\n    Suprised       0.83      0.82      0.82        89\n\n    accuracy                           0.70      1920\n   macro avg       0.71      0.71      0.71      1920\nweighted avg       0.70      0.70      0.69      1920\n\n","output_type":"stream"}]}]}